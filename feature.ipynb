{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from config.dir import DATA_DIR, EM_DATA_DIR ,REPO_DIR\n",
    "from utils.stimulus_utils import load_textgrids, load_simulated_trfiles\n",
    "from utils.textgrid import TextGrid\n",
    "from utils.dsutils import make_semantic_model, make_word_ds, make_phoneme_ds\n",
    "from utils.npp import zscore, mcorr\n",
    "import json\n",
    "from utils.SemanticModel import SemanticModel\n",
    "from utils.interpdata import lanczosinterp2D\n",
    "import pathlib\t\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip3 install numpy pandas voxelwise_tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim = 5\n",
    "#ndelays = 4\n",
    "feature =\"eng1000\"\n",
    "subject = 'sub-UTS02'\n",
    "sessions = ['10','11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_story_wordseqs(stories):\n",
    "\tgrids = load_textgrids(stories, DATA_DIR)\n",
    "\twith open( os.path.join(DATA_DIR, \"ds003020/derivative/respdict.json\"), \"r\") as f:\n",
    "\t\trespdict = json.load(f)\n",
    "\ttrfiles = load_simulated_trfiles(respdict)\n",
    "\twordseqs = make_word_ds(grids, trfiles)\n",
    "\treturn wordseqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(EM_DATA_DIR, \"sess_to_story.json\"), \"r\") as f:\n",
    "\t\tsess_to_story = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories, test_stories = [], []\n",
    "for sess in sessions:\n",
    "    stories, tstory = sess_to_story[sess][0], sess_to_story[sess][1]\n",
    "    train_stories.extend(stories)\n",
    "    if tstory not in test_stories:\n",
    "        test_stories.append(tstory)\n",
    "assert len(set(train_stories) & set(test_stories)) == 0, \"Train - Test overlap!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allstories = list(set(train_stories) | set(test_stories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving encoding model & results to: /Users/genevievelam/Documents/GitHub/stories_fmri/results/eng1000/sub-UTS02\n"
     ]
    }
   ],
   "source": [
    "save_location = os.path.join(REPO_DIR, \"results\",feature, subject)\n",
    "print(\"Saving encoding model & results to:\", save_location)\n",
    "os.makedirs(save_location, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_word_vectors(stories, word_vectors, wordseqs):\n",
    "\t\"\"\"Get Lanczos downsampled word_vectors for specified stories.\n",
    "\n",
    "\tArgs:\n",
    "\t\tstories: List of stories to obtain vectors for.\n",
    "\t\tword_vectors: Dictionary of {story: <float32>[num_story_words, vector_size]}\n",
    "\n",
    "\tReturns:\n",
    "\t\tDictionary of {story: downsampled vectors}\n",
    "\t\"\"\"\n",
    "\tdownsampled_semanticseqs = dict()\n",
    "\tfor story in stories:\n",
    "\t\tdownsampled_semanticseqs[story] = lanczosinterp2D(\n",
    "\t\t\tword_vectors[story], wordseqs[story].data_times, \n",
    "\t\t\twordseqs[story].tr_times, window=3)\n",
    "\treturn downsampled_semanticseqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eng1000_vectors(allstories):\n",
    "\t\"\"\"Get Eng1000 vectors (985-d) for specified stories.\n",
    "\n",
    "\tArgs:\n",
    "\t\tallstories: List of stories to obtain vectors for.\n",
    "\n",
    "\tReturns:\n",
    "\t\tDictionary of {story: downsampled vectors}\n",
    "\t\"\"\"\n",
    "\teng1000 = SemanticModel.load(os.path.join(EM_DATA_DIR, \"english1000sm.hf5\"))\n",
    "\twordseqs = get_story_wordseqs(allstories)\n",
    "\tvectors = {}\n",
    "\tfor story in allstories:\n",
    "\t\tsm = make_semantic_model(wordseqs[story], [eng1000], [985])\n",
    "\t\tvectors[story] = sm.data\n",
    "\treturn downsample_word_vectors(allstories, vectors, wordseqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_FEATURE_CONFIG = {\n",
    "\t#\"articulation\": get_articulation_vectors,\n",
    "\t#\"phonemerate\": get_phonemerate_vectors,\n",
    "\t#\"wordrate\": get_wordrate_vectors,\n",
    "\t\"eng1000\": get_eng1000_vectors,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_space(feature, *args):\n",
    "\treturn _FEATURE_CONFIG[feature](*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_feat = get_feature_space(feature, allstories)\n",
    "#print(\"Stimulus & Response parameters:\")\n",
    "#print(\"trim: %d, ndelays: %d\" % (trim, ndelays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_serializable(downsampled_feat):\n",
    "    \"\"\"Convert downsampled feature dictionary to a serializable format.\"\"\"\n",
    "    \n",
    "    serializable_dict = downsampled_feat.tolist()\n",
    "\n",
    "    return serializable_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_zscore_and_hrf(stories, downsampled_feat, trim):\n",
    "\t\"\"\"Get (z-scored and delayed) stimulus for train and test stories.\n",
    "\tThe stimulus matrix is delayed (typically by 2,4,6,8 secs) to estimate the\n",
    "\themodynamic response function with a Finite Impulse Response model.\n",
    "\n",
    "\tArgs:\n",
    "\t\tstories: List of stimuli stories.\n",
    "\n",
    "\tVariables:\n",
    "\t\tdownsampled_feat (dict): Downsampled feature vectors for all stories.\n",
    "\t\ttrim: Trim downsampled stimulus matrix.\n",
    "\t\tdelays: List of delays for Finite Impulse Response (FIR) model.\n",
    "\n",
    "\tReturns:\n",
    "\t\tdelstim: <float32>[TRs, features * ndelays]\n",
    "\t\"\"\"\n",
    "\tstim = [zscore(downsampled_feat[s][5+trim:-trim]) for s in stories]\n",
    "\tstim = np.vstack(stim)\n",
    "\t#delays = range(1, ndelays+1)\n",
    "\t#delstim = make_delayed(stim, delays)\n",
    "\treturn stim#delstim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "delRstim = apply_zscore_and_hrf(train_stories, downsampled_feat, trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3705, 985)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delRstim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(stories, subject):\n",
    "\t\"\"\"Get the subject\"s fMRI response for stories.\"\"\"\n",
    "\t#main_path = pathlib.Path(__file__).parent.parent.resolve()\n",
    "\tsubject_x = subject.split('-')[1]\n",
    "\tsubject_dir = os.path.join(DATA_DIR, \"ds003020/derivative/preprocessed_data/%s\" % subject_x)\n",
    "\tbase = subject_dir\n",
    "\tresp = []\n",
    "\trun_on_set = []\n",
    "\tfor story in stories:\n",
    "\t\tresp_path = os.path.join(base, \"%s.hf5\" % story)\n",
    "\t\thf = h5py.File(resp_path, \"r\")\n",
    "\t\tresp.extend(hf[\"data\"][:])\n",
    "\t\tif not run_on_set:\n",
    "\t\t\trun_on_set.append(hf[\"data\"][:].shape[0])\n",
    "\t\telse:\n",
    "\t\t\trun_on_set.append(run_on_set[-1]+hf[\"data\"][:].shape[0])\n",
    "\t\tprint(hf[\"data\"][:].shape[0], \"for story:\", story)\n",
    "\t\thf.close()\n",
    "\treturn np.array(resp), run_on_set[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326 for story: catfishingstrangerstofindmyself\n",
      "243 for story: christmas1940\n",
      "326 for story: gpsformylostidentity\n",
      "297 for story: singlewomanseekingmanwich\n",
      "325 for story: superheroesjustforeachother\n",
      "307 for story: whenmothersbullyback\n",
      "170 for story: againstthewind\n",
      "409 for story: bluehope\n",
      "237 for story: forgettingfear\n",
      "249 for story: ifthishaircouldtalk\n",
      "327 for story: lifereimagined\n",
      "489 for story: stumblinginthedark\n",
      "zRresp:  (3705, 94251)\n"
     ]
    }
   ],
   "source": [
    "# Response\n",
    "zRresp,run_on_set = get_response(train_stories, subject)\n",
    "print(\"zRresp: \", zRresp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[326, 569, 895, 1192, 1517, 1824, 1994, 2403, 2640, 2889, 3216]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_on_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_location+'/run_on.json', \"w\") as file:\n",
    "    json.dump(run_on_set,file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving encoding model & results to: /Users/genevievelam/Documents/GitHub/stories_fmri/results/eng1000/sub-UTS03\n"
     ]
    }
   ],
   "source": [
    "#save_location = os.path.join(REPO_DIR, \"results\",feature, 'sub-UTS03')\n",
    "#print(\"Saving encoding model & results to:\", save_location)\n",
    "#os.makedirs(save_location, exist_ok=True)\n",
    "\n",
    "#with open(save_location+'/fmri.json', \"w\") as file:\n",
    "#        json.dump(convert_to_serializable(zRresp),file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(save_location+'/features.json', \"w\") as file:\n",
    "#        json.dump(convert_to_serializable(delRstim),file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(save_location+'/fmri.json', \"w\") as file:\n",
    "#        json.dump(convert_to_serializable(zRresp),file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1194863,
     "sourceId": 1997650,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "naturalistic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
